{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FisSpqViA0BD"
   },
   "source": [
    "# SET UPS\n",
    "\n",
    "- installing the dependencies and packages neccessary for GPT2 (This may take ~ 1 min)\n",
    "\n",
    "- initialize environment variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgxCXGDplaTF"
   },
   "outputs": [],
   "source": [
    "# install GPT 2 via pip command \n",
    "!pip install --upgrade pip  # ensures that pip is current\n",
    "!pip install git+https://github.com/huggingface/transformers@main # install GPT2 and related dependencies\n",
    "!pip install git+https://github.com/google-research/bleurt # install bluert score and related dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_d7aBEiHH3aB"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
    "                         AdamW, get_linear_schedule_with_warmup, \\\n",
    "                         TrainingArguments, BeamScorer, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, \\\n",
    "                             RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kL3Nt76q24-X"
   },
   "outputs": [],
   "source": [
    "DEBUG           = False\n",
    "APEX_OPT_LEVEL  = 'O1'\n",
    "MODEL           = 'gpt2'\n",
    "\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "                    \n",
    "MAXLEN          = 768 # largest possible length given colab's capacities\n",
    "\n",
    "TRAIN_SIZE      = 0.8\n",
    "\n",
    "TRAIN_DATA_CKPT = 0      # position of last trained data\n",
    "TRAIN_DATA_LIMIT = 30 # ~ 1 - 1.5 hr training time for 10000 of data pts\n",
    "\n",
    "TRAIN_BATCHSIZE = 4   # largest possible batCh given colab's capacities\n",
    "BATCH_UPDATE    = 16\n",
    "\n",
    "EPOCHS          = 4\n",
    "LR              = 5e-4\n",
    "EPS             = 1e-8\n",
    "WARMUP_STEPS    = 1e2\n",
    "\n",
    "SEED            = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vpcp2k4WIA3p"
   },
   "outputs": [],
   "source": [
    "def SETSEED(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "SETSEED(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUc9jA5AjeKT"
   },
   "source": [
    "# LOAD DATA\n",
    "\n",
    "Modify the following paths according to your directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EHDIO5oVpFZf"
   },
   "outputs": [],
   "source": [
    "# path to data file\n",
    "DATA_PATH = 'recipes.csv'\n",
    "\n",
    "# path to model, 'None' if there is no model or you would like to train new model\n",
    "MODEL_PATH = 'model.bin'\n",
    "\n",
    "# directory to save model in\n",
    "SAVE_MODEL_DIR = ''\n",
    "\n",
    "# directory to save generated data in\n",
    "SAVE_DATA_DIR = 'generated_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoWIpIKOQyJQ",
    "outputId": "2093f49b-a63f-4c26-b3e0-612602deba54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount google drive if using colab, else skip\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Yc3LtdcBIQdR"
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(DATA_PATH)\n",
    "data = all_data[TRAIN_DATA_CKPT: TRAIN_DATA_CKPT + TRAIN_DATA_LIMIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6-FaU16oII-E"
   },
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, randomize=True):\n",
    "        self.randomize = randomize\n",
    "        self.tokenizer = tokenizer \n",
    "        self.ingredients = list(data['ingredients'])\n",
    "        self.instructions = list(data['instructions'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ingredients)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        input = SPECIAL_TOKENS['bos_token'] + self.ingredients[i] + SPECIAL_TOKENS['sep_token'] + \\\n",
    "                self.instructions[i] + SPECIAL_TOKENS['eos_token']\n",
    "\n",
    "        encodings_dict = self.tokenizer(input,                                   \n",
    "                                   truncation=True, \n",
    "                                   max_length=MAXLEN, \n",
    "                                   padding=\"max_length\")   \n",
    "        \n",
    "        input_ids = encodings_dict['input_ids']\n",
    "        attention_mask = encodings_dict['attention_mask']\n",
    "        \n",
    "        return {'label': torch.tensor(input_ids),\n",
    "                'input_ids': torch.tensor(input_ids), \n",
    "                'attention_mask': torch.tensor(attention_mask)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kO-1Q4PAKjFU"
   },
   "outputs": [],
   "source": [
    "def get_tokenier(special_tokens):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)  \n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(tokenizer, special_tokens, load_model_path=None):\n",
    "\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(MODEL, \n",
    "                                        bos_token_id=tokenizer.bos_token_id,\n",
    "                                        eos_token_id=tokenizer.eos_token_id,\n",
    "                                        sep_token_id=tokenizer.sep_token_id,\n",
    "                                        pad_token_id=tokenizer.pad_token_id,\n",
    "                                        output_hidden_states=False)\n",
    "   \n",
    "\n",
    "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if load_model_path:\n",
    "        model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "    model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5iUkC0djQZg"
   },
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UBPvguO8KZIe"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenier(SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  SPECIAL_TOKENS,\n",
    "                  load_model_path= MODEL_PATH\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGNXT1AmhEuV"
   },
   "source": [
    "# Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "jBrfzbmkKvJL",
    "outputId": "ea619e49-8c80-415b-ad56-cb55104b6ec7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'TRAINING SMAPLES: 80 || TESTING SAMPLES: 20'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.iloc[0:int(len(data)*TRAIN_SIZE), :]\n",
    "val_data = data.iloc[int(len(data)*TRAIN_SIZE):, :]\n",
    "\n",
    "train_dataset = RecipeDataset(train_data, tokenizer)\n",
    "val_dataset = RecipeDataset(val_data, tokenizer, randomize=False)\n",
    "\n",
    "f'TRAINING SMAPLES: {len(train_dataset) :,} || TESTING SAMPLES: {len(val_dataset) :,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "id": "_dDRW1V0Nu-g",
    "outputId": "83f86ee0-cec9-4018-cdb7-75d467632e8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:27, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.457684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /content/\n",
      "Configuration saved in /content/config.json\n",
      "Model weights saved in /content/pytorch_model.bin\n",
      "tokenizer config file saved in /content/tokenizer_config.json\n",
      "Special tokens file saved in /content/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
    "    gradient_accumulation_steps=BATCH_UPDATE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    fp16_opt_level=APEX_OPT_LEVEL,\n",
    "    warmup_steps=WARMUP_STEPS,    \n",
    "    learning_rate=LR,\n",
    "    adam_epsilon=EPS,\n",
    "    weight_decay=0.01,        \n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,    \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKCNDxU5jYaR"
   },
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DlNnwh_VV5cy"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'TEST-model.bin'\n",
    "path = SAVE_MODEL_DIR + MODEL_NAME\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ_rG2IpgONB"
   },
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UHgnSc5W3M-P"
   },
   "outputs": [],
   "source": [
    "#ingredient = list(data['ingredients'])[0]\n",
    "ingredient = \"Ingredients: 1. 2 pound of beef 2. 1 cup of water 3. 1 cup of coffee 4. 1 cup of cream 5. 1 tablespoon of salt 6. 2 tablespoon of sugar 7. 2 cup of cheese 8. 1 onion 9. 1 cup of flour\"\n",
    "\n",
    "prompt = SPECIAL_TOKENS['bos_token']  + ingredient + SPECIAL_TOKENS['sep_token']\n",
    "         \n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "device = torch.device(\"cuda\")\n",
    "generated = generated.to(device)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ce-RZrSR3iGL"
   },
   "outputs": [],
   "source": [
    "sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                min_length=50, \n",
    "                                max_length=MAXLEN,\n",
    "                                top_k=30,                                 \n",
    "                                top_p=0.7,        \n",
    "                                temperature=1.5,\n",
    "                                repetition_penalty=1.0,\n",
    "                                num_return_sequences=10\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1Dgc-rC4LPa",
    "outputId": "49a36af5-add6-4ae5-caff-c4a2c9f99da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients: 1. 2 cups flour 2. 1 tablespoon cinnamon 3. 2 teaspoons baking soda 4. 1 teaspoon salt 5. 14 teaspoon baking powder 6. 3 eggs 7. 2 cups sugar 8. 1 cup vegetable oil 9. 1 tablespoon vanilla 10. 2 cups zucchini 11. 1 cup walnuts \n",
      "----------\n",
      "\n",
      "Instructions: 1. Sift flour, cinnamon, baking soda, salt, and baking powder together into mixing bowl. 2. Make a well in the center, and pour in the eggs and sugar. 3. Stir together until blended. 4. Fold in vanilla and zucchini, nuts, and flour until well mixed. 5. Spoon batter into two greased and floured loaf pans, and bake at 350 degrees for one hour, or until done. 6. Let cool for 20 minutes before removing from pans. \n",
      "\n",
      "Instructions: 1. Combine first 8 ingredients in large bowl. 2. Beat with electric mixer on medium speed 3 minutes or until fluffy. 3. Stir in zucchini and nuts. 4. Pour into greased 8-inch square baking pan. 5. Bake at 350 degrees for 30 minutes or until toothpick inserted in center comes out clean. 6. Cool completely on wire rack. 7. Cover; store at room temperature. \n",
      "\n",
      "Instructions: 1. Combine flour, cinnamon, baking soda, salt and baking powder in a bowl. 2. In another bowl, combine eggs, sugar, oil and vanilla and mix. 3. Add to dry ingredients, stirring just until combined. 4. Fold in zucchini, walnuts and cranberries. 5. Spoon into a greased 8-by-8-inch pan. 6. Bake at 350 degrees for about 40-45 minutes or until toothpick inserted comes out clean. 7. Let cool in pan 5 minutes, then invert onto wire rack and cool completely. 8. Cut into bars. \n",
      "\n",
      "Instructions: 1. Preheat oven to 375 degrees. 2. Mix dry ingredients. 3. Mix wet ingredients. 4. Combine dry ingredients. 5. Add oil, zucchini, and nuts. 6. Bake for 35 minutes or until brownies pull away from side of pan. \n",
      "\n",
      "Instructions: 1. Mix first 4 ingredients, set aside. 2. In a large bowl, beat eggs. 3. Stir in sugar, oil, vanilla and egg mixture, mix until smooth. 4. Stir in zucchini and nuts. 5. Pour into well greased 9x9-inch pan and bake at 350 degrees for 30 minutes or until tests done. 6. Cool completely. \n",
      "\n",
      "Instructions: 1. Mix dry ingredients well, set aside. 2. Mix egg replacer, sugar, oil and vanilla, add to dry ingredients and stir until just moistened. 3. Fold in zucchini and nuts. 4. Spoon into greased and floured 9x5 inch loaf pan. 5. Bake at 350 for 45 minutes. \n",
      "\n",
      "Instructions: 1. Mix first five ingredients. 2. Beat eggs and oil in large bowl. 3. Add sugar and mix well. 4. Add all remaining ingredients and mix well. 5. Pour into two loaf pans and bake at 350 for 50 minutes to 1 hour or until tests done. \n",
      "\n",
      "Instructions: 1. Sift flour, cinnamon, baking soda, salt and baking powder together. 2. In a seperate bowl, whisk together eggs and sugar until well blended. 3. Stir in oil, vanilla and zucchini. 4. Fold dry ingredients into zucchini mixture just until moistened. 5. Fold in nuts. 6. Spoon batter into paper lined muffin tins. 7. Bake in 375 F oven for 15 to 20 minutes or until a toothpick inserted comes out clean. 8. Cool in muffin tins for 10 minutes before removing to cool completely on wire racks. \n",
      "\n",
      "Instructions: 1. Preheat oven to 350F 2. Combine all dry ingredients in a small bowl. 3. Make a well in the middle and add eggs, sugar, oil, vanilla, and zucchini. 4. Beat thoroughly. 5. Stir in the nuts and pour into a well greased 9 x 13 inch pan. 6. Bake for 45 minutes to 1 hour or until tests done. \n",
      "\n",
      "Instructions: 1. Combine the first four ingredients in a bowl. 2. Beat in the eggs and oil. 3. Add the sugar and vanilla and beat for 10 minutes. 4. Mix in the zucchini and nuts. 5. Pour into a well-greased muffin tin. 6. Bake in a 375 degree oven for 25-30 minutes or until lightly browned. 7. Let cool in the pan for 5 minutes, then turn onto a wire rack to cool completely. 8. Store in an airtight container. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    if i == 0:\n",
    "      print(text.split('Instructions:')[0], '\\n', '-'*10, '\\n', sep = '')\n",
    "    print('Instructions:', text.split('Instructions:')[1], '\\n', sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyAYclm8x400"
   },
   "source": [
    "# Generate Validation Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wmQwHgl-x4pp"
   },
   "outputs": [],
   "source": [
    "SAVE_DATA_FILE_NAME = 'validation_data.csv'\n",
    "test_data = all_data[:10] \n",
    "validation_df = pd.DataFrame(columns = [\"truth\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ogFWT6T2yMiS"
   },
   "outputs": [],
   "source": [
    "for i, row in test_data.iterrows():\n",
    "\n",
    "  prompt = SPECIAL_TOKENS['bos_token']  + row[\"ingredients\"] + SPECIAL_TOKENS['sep_token']\n",
    "        \n",
    "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "  device = torch.device(\"cuda\")\n",
    "  generated = generated.to(device)\n",
    "\n",
    "  model.eval()\n",
    "  sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                min_length=50, \n",
    "                                max_length=MAXLEN,\n",
    "                                top_k=30,                                 \n",
    "                                top_p=0.7,        \n",
    "                                temperature=1.5,\n",
    "                                repetition_penalty=1.0,\n",
    "                                num_return_sequences=3)\n",
    "  for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    text = text.split(\"Instructions:\")[1]\n",
    "    #print(text)\n",
    "    validation_df = validation_df.append({\n",
    "        'truth' : row[\"instructions\"],\n",
    "        'prediction': \"Instructions:\" + text\n",
    "    }, ignore_index=True)\n",
    "\n",
    "#validation_df.to_csv(SAVE_DATA_DIR + SAVE_DATA_FILE_NAME)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CblKvojmsQOo"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXOzc33msiTS",
    "outputId": "7748092c-dd2c-4572-df1a-70ae9ea6fe14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No checkpoint specified, defaulting to BLEURT-tiny.\n",
      "INFO:tensorflow:Reading checkpoint /usr/local/lib/python3.7/dist-packages/bleurt/test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "references = validation_df['truth']\n",
    "candidates = validation_df['prediction']\n",
    "\n",
    "scorer = score.BleurtScorer()\n",
    "scores = scorer.score(references=references, candidates=candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "rJO_v3YozVzh",
    "outputId": "674ad1c7-93cb-467d-c8fb-1b15467a6dc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ce58f369-2f0a-4716-8880-5adad2c04786\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.453432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.071038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.604296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.395737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.296551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.094377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce58f369-2f0a-4716-8880-5adad2c04786')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ce58f369-2f0a-4716-8880-5adad2c04786 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ce58f369-2f0a-4716-8880-5adad2c04786');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               0\n",
       "count  30.000000\n",
       "mean   -0.453432\n",
       "std     0.288420\n",
       "min    -1.071038\n",
       "25%    -0.604296\n",
       "50%    -0.395737\n",
       "75%    -0.296551\n",
       "max     0.094377"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).describe()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPT2_playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
